---
title: "En Busca del Modelo Perdido - Parte 6: La Primera Reliquia"
layout: single
author_profile: false
related: true
comments: true
toc: false

sidebar:
  nav: "modelo_perdido"

classes: wide

header:
  image: /assets/images/PAES_prediction_model/RandomForestBanner.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestBanner.jpg

categories:
  - Machine Learning

tags:
  - Random Forest
  - Validaci√≥n Cruzada
  - Optimizaci√≥n de Modelos
  - Predicci√≥n de Resultados
  - PAES
  - Aprendanza
  - Data Science
  - Aprendizaje Autom√°tico
  - Data Analysis

---
<div align="justify" markdown="1">
La odisea contin√∫a en "En Busca del Modelo Perdido", y en este episodio, titulado "La Primera Reliquia", desvelamos un hallazgo crucial en nuestro viaje hacia un modelo robusto de predicci√≥n de resultados de la PAES a nivel escolar.

## üß≠ Descifrando el Mapa hacia la Primera Reliquia üó∫Ô∏è

Nuestro viaje en el universo del an√°lisis de datos nos lleva a un descubrimiento esencial: la afinaci√≥n precisa de nuestro modelo Random Forest. Al profundizar en los secretos de la programaci√≥n y sus impactos, hemos dado con un dato clave: el heatmap que relaciona la precisi√≥n del modelo con los valores de `n_estimators` y `num_folds`. El an√°lisis de este gr√°fico es crucial para definir el modelo que nos dar√° la confiabilidad necesaria para establecer las predicciones finales.

## üåü El Desaf√≠o de los Par√°metros: `n_estimators` y `num_folds`

El coraz√≥n de nuestra indagaci√≥n se centra en dos par√°metros cruciales: `n_estimators` y `num_folds` en la validaci√≥n cruzada. La elecci√≥n no es trivial, ya que cada ajuste puede influir significativamente en la precisi√≥n y eficiencia de nuestro modelo.

### üåê Patrones en el Heatmap: Folds como Factor Dominante
Al analizar el heatmap interactivo de MAE, un patr√≥n interesante sali√≥ a la luz: la dependencia de los resultados con el n√∫mero de folds. Observamos patrones horizontales claros, lo que indica que el n√∫mero de folds tiene un impacto m√°s significativo en el MAE que el n√∫mero de estimadores.

Este hallazgo fue crucial para nuestro an√°lisis. Aunque los n_estimators tienen cierta influencia, especialmente hasta el valor de 200, cualquier n√∫mero m√°s all√° de este punto no parec√≠a afectar significativamente los resultados del modelo (no hay l√≠neas verticales que hablen de fluctuaciones significativas). Esto sugiere que alcanzamos un l√≠mite en la precisi√≥n del modelo con respecto a n_estimators, y la atenci√≥n deber√≠a centrarse en optimizar el n√∫mero de folds para un equilibrio adecuado entre precisi√≥n y generalizaci√≥n.

<figure style = "float: center; width: 100%; text-align: center; object-fit: contain;">
  <embed type="text/html" src="/assets/images/PAES_prediction_model/heatmap_interactivo.html" width="100%" height="50%" alt="Imagen 1: Heatmap del An√°lisis de MAE.">
  <figcaption>Imagen 1: Heatmap que muestra c√≥mo var√≠an los valores de MAE con diferentes combinaciones de 'n_estimators' y 'num_folds'.</figcaption>
</figure>

### üìê Ajustando el Enfoque: MAE, Folds y Estimadores üìä
Continuando en nuestro periplo, el an√°lisis de la estabilidad de los valores de folds se hizo imprescindible. Como puedes notar en el gr√°fico interactivo, los valores de 3, 5 y 14 en la cantidad de folds parecen mostrar los valores m√°s bajos y significativos para MAE. Utilizamos un gr√°fico de dispersi√≥n para entender mejor c√≥mo el MAE cambia con diferentes n√∫meros de estimadores y estos valores para los folds. El resultado se muestra a continuaci√≥n.

<figure style = "float: center; width: 100%; text-align: center;">
  <img src="/assets/images/PAES_prediction_model/folds_stability_analysis.png" width="100%"  alt="Imagen 2: An√°lisis de la Estabilidad de los Folds">
  <figcaption>Imagen 2: An√°lisis de la Estabilidad de los Folds 3, 5 y 14 en funci√≥n del n√∫mero de estimadores.</figcaption>
</figure>

Este gr√°fico me ayud√≥ a comprender la relaci√≥n entre el n√∫mero de estimadores y el MAE para cada uno de estos n√∫meros de folds espec√≠ficos. A manera de an√°lisis, creo que es importante que notes que los folds 3 y 5 tienden a minimizar el MAE a partir del valor 700 aproximadamente. El fold 14 (color amarillo) se mantiene ligeramente m√°s arriba que estos dos lo cual hace que descartemos su uso.

En vista de que hay una estabilidad importante para los fold 3 y 5 en el rango de 600 y 1000 de n_estimators seleccion√© un valor intermedio para asegurar de alguna manera la estabilidad del modelo (no cerca del borde inferior o exterior del rango). Como una mayor cantidad de folds ayuda a mejorar la generacionaci√≥n y entrenamiento del modelo, entonces privilegiamos 5 por sobre 3.

## üßê Justificaci√≥n de la Elecci√≥n: Equilibrio entre Precisi√≥n y Generalizaci√≥n
Por el an√°lisis anterior, nuestra elecci√≥n se basa en una justificaci√≥n s√≥lida. La combinaci√≥n de n_estimators=800 y num_folds=5 no solo mostr√≥ un MAE mejor que el promedio, sino que tambi√©n indic√≥ estabilidad y robustez. Esta configuraci√≥n asegura que el modelo es preciso, pero tambi√©n generalizable a nuevos datos, un equilibrio crucial en la ciencia de datos.

## üõ†Ô∏è Construyendo el Modelo: El C√≥digo Final üßë‚Äçüíª

Despu√©s de un an√°lisis detallado y la elecci√≥n cuidadosa de los par√°metros, procedimos a construir el modelo final de Random Forest. El siguiente c√≥digo refleja la culminaci√≥n de nuestros esfuerzos:

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_predict, KFold
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Cargar los datos desde el archivo CSV
csv_filename = "PAES_training_set_2022_Complete - PAES_training_set_2022 - Matem√°ticas.csv"
data = pd.read_csv(csv_filename)

# Eliminar filas con valores faltantes
data = data.dropna()

# Convertir columnas num√©ricas a tipos de datos num√©ricos
numeric_columns = data.columns.difference(['ID', 'Curso', 'Nombre', 'PAES'])
data[numeric_columns] = data[numeric_columns].astype(float)

# Dividir los datos en caracter√≠sticas (X) y objetivo (y)
X = data.drop(['ID', 'Curso', 'Nombre', 'PAES'], axis=1)
y = data['PAES']

# Normalizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Construir el modelo Random Forest Regressor
rf_regressor = RandomForestRegressor(n_estimators=800, random_state=42)

# Crear objeto KFold con el n√∫mero de folds deseado
num_folds = 5
kf = KFold(n_splits=num_folds)

# Realizar validaci√≥n cruzada con cross_val_predict
y_pred = cross_val_predict(rf_regressor, X_scaled, y, cv=kf)

# Obtener la importancia de las caracter√≠sticas
rf_regressor.fit(X_scaled, y)
feature_importances = rf_regressor.feature_importances_

# Obtener las columnas correspondientes a las caracter√≠sticas
feature_columns = X.columns

# Obtener las 5 caracter√≠sticas m√°s importantes
top_features_indices = feature_importances.argsort()[-5:][::-1]
top_features = feature_columns[top_features_indices]
top_feature_importances = feature_importances[top_features_indices]

print("Caracter√≠sticas m√°s importantes:")
for i, (feature, importance) in enumerate(zip(top_features, top_feature_importances)):
    print(f"{i+1}. {feature}: {importance:.4f}")

# Gr√°fico de valores reales vs. predicciones
plt.figure(figsize=(10, 6))
plt.scatter(y, y_pred, alpha=0.5)
plt.xlabel('Valor Real de PAES')
plt.ylabel('Predicci√≥n de PAES')
plt.title('Valores Reales vs. Predicciones')
plt.grid()
plt.show()
```

Podr√°s notar que como valor agregado hemos hecho que se entreguen los elementos de la tabla original de datos que puedan ser m√°s significativos para la construcci√≥n del modelo. Esto nos da luces de qu√© es lo que quiz√°s pueda ocurrir a lo largo de ls ensayos o mediciones que podr√≠a ayudar a corregir el proceso de aprendizaje. El resultado de todo se muestra a continuaci√≥n:

Caracter√≠sticas m√°s importantes:
1. EnsayoSeptiembre: 0.2947
2. EnsayoJunio: 0.2383
3. EnsayoOctubre: 0.1460
4. EnsayoNoviembre: 0.1094
5. EnsayoAgosto: 0.0870

<figure style = "float: center; width: 100%; text-align: center; font-style: italic; font-size: 0.7em; text-indent: 0; margin: 0.6em; padding: 0.8em;">
  <a href="/assets/images/PAES_prediction_model/modelo_paes1.png">
    <img src="/assets/images/PAES_prediction_model/modelo_paes1.png" width="100%"  alt="Imagen 3: Resultado del modelo de random forest ajustado y valores reales obtenidos en la PAES.">
  </a>
  <figcaption>Imagen 3: Resultado del modelo de random forest ajustado y valores reales obtenidos en la PAES.</figcaption>
</figure>

Este c√≥digo incorpora la normalizaci√≥n de los datos, el uso de Random Forest con los par√°metros seleccionados y la validaci√≥n cruzada. Adem√°s, proporciona una visualizaci√≥n de las predicciones del modelo frente a los valores reales de PAES que concluyen con un excelente error de unos 50 puntos. 

Puede parecer mucho, pero en los niveles en los que se tienen los resultados, **cada pregunta de la PAES pesa entre unos 17 y 20 puntos, por lo que el error de nuestro modelo de predicci√≥n es en el peor de los casos de 3 preguntas, lo cual es incre√≠blemente notable considerando la base de datos que tenemos para partir**.

## üìà An√°lisis de Residuos: Comprendiendo el Error del Modelo
Para evaluar a√∫n m√°s el rendimiento de nuestro modelo, realizamos un an√°lisis de residuos. Esto ayudar√° a entender d√≥nde se concentraban los datos y a visibilizar el nivel de error del modelo de manera m√°s clara.

<figure style = "float: center; width: 100%; text-align: center; font-style: italic; font-size: 0.7em; text-indent: 0; margin: 0.6em; padding: 0.8em;">
  <a href="/assets/images/PAES_prediction_model/residuos_paes1.png">
    <img src="/assets/images/PAES_prediction_model/residuos_paes1.png" width="100%"  alt="Imagen 4: Analisis de residuos entre el modelo predictivo, los valores reales y la distribuci√≥n de los resultados en cada eje.">
  </a>
  <figcaption>Imagen 4: Analisis de residuos entre el modelo predictivo, los valores reales y la distribuci√≥n de los resultados en cada eje.</figcaption>
</figure>

Este an√°lisis gr√°fico nos proporciona una perspectiva detallada de la distribuci√≥n de los errores de nuestro modelo. Aqu√≠ ya podemos notar que la confiabilidad del modelo es robusta ya que la mayor√≠a de las diferencias se mueve en valores que van de -50 a 50 puntos. 

La mayor poblaci√≥n de resultados se mueve en un rango superior a los 850 puntos por lo que debemos considerar que esta es una poblaci√≥n de estudiantes que en general tuvieron buenos resultados en la prueba PAES. Para mejorar los rangos inferiores habr√≠a que tener m√°s datos y de estudiantes con esas realidades para as√≠ afinar m√°s la predicci√≥n.

## üöÄ Hacia el Futuro: La Importancia de la Primera Reliquia
Este descubrimiento, la Primera Reliquia, no es solo un paso en nuestra saga, sino una base s√≥lida para futuras exploraciones. Con un modelo bien afinado, estamos m√°s cerca de desvelar los secretos de la PAES y su predicci√≥n a nivel escolar.

En el pr√≥ximo cap√≠tulo, continuaremos nuestra aventura, llevando nuestra Primera Reliquia hacia nuevos horizontes y desaf√≠os. Mant√©nganse atentos, aprendanzantes, la b√∫squeda contin√∫a...

<div align="right" markdown="1">
Hasta el pr√≥ximo cronopunto del Principia ü•ö.

DV

</div>
</div>