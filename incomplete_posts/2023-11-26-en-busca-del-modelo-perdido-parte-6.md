---
title: "En Busca del Modelo Perdido - Parte 6: La Primera Reliquia"
layout: single
author_profile: true
related: true
comments: true
toc: false

sidebar:
  nav: "modelo_perdido"

classes: wide

header:
  image: /assets/images/PAES_prediction_model/RandomForestBanner.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestBanner.jpg

categories:
  - Machine Learning

tags:
  - Random Forest
  - Validaci√≥n Cruzada
  - Optimizaci√≥n de Modelos
  - Predicci√≥n de Resultados
  - PAES
  - Aprendanza
  - Data Science
  - Aprendizaje Autom√°tico
  - Data Analysis

---
<div align="justify" markdown="1">
La odisea contin√∫a en "En Busca del Modelo Perdido", y en este episodio, titulado "La Primera Reliquia", desvelamos un hallazgo crucial en nuestro viaje hacia un modelo robusto de predicci√≥n de resultados de la PAES a nivel escolar.

## üß≠ Descifrando el Mapa hacia la Primera Reliquia üó∫Ô∏è

Nuestro viaje en el universo del an√°lisis de datos nos lleva a un descubrimiento esencial: la afinaci√≥n precisa de nuestro modelo Random Forest. Al profundizar en los secretos de la programaci√≥n y sus impactos, hemos dado con la primera reliquia: una configuraci√≥n √≥ptima de par√°metros que marca el camino hacia predicciones confiables.

### üåü El Desaf√≠o de los Par√°metros: `n_estimators` y `num_folds`

El coraz√≥n de nuestra indagaci√≥n se centra en dos par√°metros cruciales: `n_estimators` y `num_folds` en la validaci√≥n cruzada. La elecci√≥n no es trivial, ya que cada ajuste puede influir significativamente en la precisi√≥n y eficiencia de nuestro modelo.

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score, KFold

# Configuramos la validaci√≥n cruzada y el Random Forest
kf = KFold(n_splits=5)
model = RandomForestRegressor(n_estimators=800, random_state=42)
```

La decisi√≥n de 800 √°rboles y 5 folds no fue aleatoria. Despu√©s de una exhaustiva experimentaci√≥n, representada en un mapa de calor, identificamos que esta combinaci√≥n proporcionaba un balance ideal entre precisi√≥n (bajo MAE) y generalizaci√≥n.

## üìä Analizando el Heatmap: Una Visi√≥n Clara del MAE
El an√°lisis del heatmap fue revelador. Mostr√≥ c√≥mo diferentes combinaciones de n_estimators y num_folds afectan el Error Absoluto Medio (MAE). Nuestra elecci√≥n de 800 y 5, respectivamente, destac√≥ por ofrecer un MAE sustancialmente bajo, lo que indica una alta precisi√≥n en las predicciones.

<figure style = "float: center; width: 100%; height: 500px; text-align: center; object-fit: contain;">
  <embed type="text/html" src="/assets/images/PAES_prediction_model/heatmap_interactivo.html" width="100%" height="100%" alt="Imagen 1: Heatmap del An√°lisis de MAE.">
  <figcaption>Imagen 1: Heatmap que muestra c√≥mo var√≠an los valores de MAE con diferentes combinaciones de 'n_estimators' y 'num_folds'.</figcaption>
</figure>


## üßê Justificaci√≥n de la Elecci√≥n: Equilibrio entre Precisi√≥n y Generalizaci√≥n
Nuestra elecci√≥n se basa en una justificaci√≥n s√≥lida. La combinaci√≥n de n_estimators=800 y num_folds=5 no solo mostr√≥ un MAE mejor que el promedio, sino que tambi√©n indic√≥ estabilidad y robustez. Esta configuraci√≥n asegura que el modelo es preciso, pero tambi√©n generalizable a nuevos datos, un equilibrio crucial en la ciencia de datos.

### üìê Ajustando el Enfoque: MAE, Folds y Estimadores üìä
Continuando en nuestro periplo, el an√°lisis de la estabilidad de los valores de folds se hizo imprescindible. Utilizamos un gr√°fico de dispersi√≥n para entender mejor c√≥mo el MAE cambia con diferentes n√∫meros de estimadores, enfoc√°ndonos en los folds 3, 5 y 14, que hab√≠an mostrado un comportamiento prometedor.

<figure style = "float: center; width: 100%; text-align: center;">
  <img src="/assets/images/PAES_prediction_model/folds_stability_analysis.png" width="100%"  alt="Imagen 2: An√°lisis de la Estabilidad de los Folds">
  <figcaption>Imagen 2: An√°lisis de la Estabilidad de los Folds 3, 5 y 14 en funci√≥n del n√∫mero de estimadores.</figcaption>
</figure>

Este an√°lisis nos ayud√≥ a comprender la relaci√≥n entre el n√∫mero de estimadores y el MAE para cada uno de estos n√∫meros de folds espec√≠ficos, siendo un factor determinante en nuestra elecci√≥n del n√∫mero de folds.

## üåê Patrones en el Heatmap: Folds como Factor Dominante
Al analizar el heatmap interactivo de MAE, un patr√≥n interesante sali√≥ a la luz: la dependencia de los resultados en el n√∫mero de folds. Observamos patrones horizontales claros, lo que indica que el n√∫mero de folds tiene un impacto m√°s significativo en el MAE que el n√∫mero de estimadores.

Este hallazgo fue crucial para nuestro an√°lisis. Aunque los n_estimators tienen cierta influencia, especialmente hasta el valor de 200, cualquier n√∫mero m√°s all√° de este punto no parec√≠a afectar significativamente los resultados del modelo. Esto sugiere que alcanzamos un l√≠mite en la precisi√≥n del modelo con respecto a n_estimators, y la atenci√≥n deber√≠a centrarse en optimizar el n√∫mero de folds para un equilibrio adecuado entre precisi√≥n y generalizaci√≥n.

<figure style = "float: center; width: 100%; text-align: center;">
  <embed type="text/html" src="/assets/images/PAES_prediction_model/heatmap_interactivo.html" width="100%"  alt="Imagen 3: Heatmap de Dependencia de Folds">
  <figcaption>Imagen 3: Heatmap mostrando la dependencia del MAE en el n√∫mero de folds, con patrones horizontales que indican su impacto predominante.</figcaption>
</figure>

## üõ†Ô∏è Construyendo el Modelo: El C√≥digo Final üßë‚Äçüíª

Despu√©s de un an√°lisis detallado y la elecci√≥n cuidadosa de los par√°metros, procedimos a construir el modelo final de Random Forest. El siguiente c√≥digo refleja la culminaci√≥n de nuestros esfuerzos:

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_predict, KFold
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Cargar los datos desde el archivo CSV
csv_filename = "PAES_training_set_2022_Complete - PAES_training_set_2022 - Matem√°ticas.csv"
data = pd.read_csv(csv_filename)

# Eliminar filas con valores faltantes
data = data.dropna()

# Convertir columnas num√©ricas a tipos de datos num√©ricos
numeric_columns = data.columns.difference(['ID', 'Curso', 'Nombre', 'PAES'])
data[numeric_columns] = data[numeric_columns].astype(float)

# Dividir los datos en caracter√≠sticas (X) y objetivo (y)
X = data.drop(['ID', 'Curso', 'Nombre', 'PAES'], axis=1)
y = data['PAES']

# Normalizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Construir el modelo Random Forest Regressor
rf_regressor = RandomForestRegressor(n_estimators=800, random_state=42)

# Crear objeto KFold con el n√∫mero de folds deseado
num_folds = 5
kf = KFold(n_splits=num_folds)

# Realizar validaci√≥n cruzada con cross_val_predict
y_pred = cross_val_predict(rf_regressor, X_scaled, y, cv=kf)

# Obtener la importancia de las caracter√≠sticas
rf_regressor.fit(X_scaled, y)
feature_importances = rf_regressor.feature_importances_

# Obtener las columnas correspondientes a las caracter√≠sticas
feature_columns = X.columns

# Obtener las 5 caracter√≠sticas m√°s importantes
top_features_indices = feature_importances.argsort()[-5:][::-1]
top_features = feature_columns[top_features_indices]
top_feature_importances = feature_importances[top_features_indices]

print("Caracter√≠sticas m√°s importantes:")
for i, (feature, importance) in enumerate(zip(top_features, top_feature_importances)):
    print(f"{i+1}. {feature}: {importance:.4f}")

# Gr√°fico de valores reales vs. predicciones
plt.figure(figsize=(10, 6))
plt.scatter(y, y_pred, alpha=0.5)
plt.xlabel('Valor Real de PAES')
plt.ylabel('Predicci√≥n de PAES')
plt.title('Valores Reales vs. Predicciones')
plt.grid()
plt.show()
```

El resultado se muestra a continuaci√≥n:

<figure style = "float: center; width: 100%; text-align: center;">
  <embed type="text/html" src="/assets/images/PAES_prediction_model/modelo_paes1.png" width="100%"  alt="Imagen 3: Heatmap de Dependencia de Folds">
  <figcaption>Imagen 3: Heatmap mostrando la dependencia del MAE en el n√∫mero de folds, con patrones horizontales que indican su impacto predominante.</figcaption>
</figure>

Este c√≥digo incorpora la normalizaci√≥n de los datos, el uso de Random Forest con los par√°metros seleccionados y la validaci√≥n cruzada. Adem√°s, proporciona una visualizaci√≥n de las predicciones del modelo frente a los valores reales de PAES.

## üìà An√°lisis de Residuos: Comprendiendo el Error del Modelo
Para evaluar a√∫n m√°s el rendimiento de nuestro modelo, realizamos un an√°lisis de residuos. Esto nos ayud√≥ a entender d√≥nde se concentraban los datos y a medir el nivel de error del modelo.

```python
import matplotlib.pyplot as plt
import numpy as np

# Calcula los residuos
residuos = y - y_pred

# Calcula la media y la desviaci√≥n est√°ndar de los residuos
media_residuos = np.mean(residuos)
desviacion_estandar_residuos = np.std(residuos)

# Define las l√≠neas para las desviaciones est√°ndar
linea_1_std = media_residuos + desviacion_estandar_residuos
linea_2_std = media_residuos + 2 * desviacion_estandar_residuos
linea_m1_std = media_residuos - desviacion_estandar_residuos
linea_m2_std = media_residuos - 2 * desviacion_estandar_residuos

# Crea una figura y un arreglo de subplots
fig = plt.figure(figsize=(16, 8))
grid = plt.GridSpec(4, 4, hspace=0.2, wspace=0.2)

# Gr√°fico de dispersi√≥n principal
ax_main = fig.add_subplot(grid[1:4, 0:3])
ax_x_hist = fig.add_subplot(grid[0, 0:3], sharex=ax_main)
ax_y_hist = fig.add_subplot(grid[1:4, 3], sharey=ax_main)

# Gr√°fico de dispersi√≥n principal
ax_main.scatter(y_pred, residuos, alpha=0.5)
ax_main.axhline(y=0, color='red', linestyle='--', linewidth=1)
ax_main.axhline(y=linea_1_std, color='green', linestyle='--', linewidth=1, label='1st Std Dev')
ax_main.axhline(y=linea_2_std, color='orange', linestyle='--', linewidth=1, label='2nd Std Dev')
ax_main.axhline(y=linea_m1_std, color='green', linestyle='--', linewidth=1)
ax_main.axhline(y=linea_m2_std, color='orange', linestyle='--', linewidth=1)

# √Åreas sombreadas entre las desviaciones est√°ndar en el eje Y
ax_main.fill_betweenx([linea_m2_std, linea_2_std], min(y_pred), max(y_pred), color='orange', alpha=0.04, label='-2nd--1st Std Dev')
ax_main.fill_betweenx([linea_m1_std, linea_1_std], min(y_pred), max(y_pred), color='green', alpha=0.1, label='1st-2nd Std Dev')

ax_main.set_xlim([min(y_pred), max(y_pred)])  # Ajusta los l√≠mites del eje X
ax_main.set_xlabel('Predicci√≥n de PAES')
ax_main.set_ylabel('Residuos')
ax_main.legend()

# Histograma en el eje X (predicciones)
ax_x_hist.hist(y_pred, bins=30, edgecolor='k')
ax_x_hist.set_xlabel('Predicci√≥n de PAES')

# Histograma en el eje Y (residuos)
ax_y_hist.hist(residuos, bins=30, orientation='horizontal', edgecolor='k')
ax_y_hist.set_ylabel('Residuos')

plt.show()
```

<figure style = "float: center; width: 100%; text-align: center;">
  <embed type="text/html" src="/assets/images/PAES_prediction_model/residuos_paes1.png" width="100%"  alt="Imagen 3: Heatmap de Dependencia de Folds">
  <figcaption>Imagen 3: Heatmap mostrando la dependencia del MAE en el n√∫mero de folds, con patrones horizontales que indican su impacto predominante.</figcaption>
</figure>

Este an√°lisis gr√°fico nos proporciona una perspectiva detallada de la distribuci√≥n de los errores de nuestro modelo, permiti√©ndonos identificar patrones y √°reas de mejora.

## üöÄ Hacia el Futuro: La Importancia de la Primera Reliquia
Este descubrimiento, la Primera Reliquia, no es solo un paso en nuestra saga, sino una base s√≥lida para futuras exploraciones. Con un modelo bien afinado, estamos m√°s cerca de desvelar los secretos de la PAES y su predicci√≥n a nivel escolar.

En el pr√≥ximo cap√≠tulo, continuaremos nuestra aventura, llevando nuestra Primera Reliquia hacia nuevos horizontes y desaf√≠os. Mant√©nganse atentos, aprendanzantes, la b√∫squeda contin√∫a...

<div align="right" markdown="1">
Hasta el pr√≥ximo cronopunto del Principia ü•ö.

DV

</div>
</div>