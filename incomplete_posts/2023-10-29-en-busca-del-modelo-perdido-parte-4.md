---
title: "En Busca del Modelo Perdido - Parte 4: Los Secretos del Random Forest"
layout: single
author_profile: true
related: true
comments: true
toc: false

header:
  image: /assets/images/PAES_prediction_model/RandomForestBanner.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestBanner.jpg

categories:
  - Machine Learning
  - Aprendizaje Autom치tico
  - Data Science
  - Ciencia de Datos
  - Model Building
  - Construcci칩n de Modelos
tags:
  - Random Forest
  - Bosque Aleatorio
  - Decision Trees
  - 츼rboles de Decisi칩n
  - Machine Learning Models
  - Modelos de Aprendizaje Autom치tico
  - Model Evaluation
  - Evaluaci칩n de Modelos
  - Feature Engineering
  - Ingenier칤a de Caracter칤sticas
  - Python Programming
  - Programaci칩n en Python
  - Data Preprocessing
  - Procesamiento de Datos
  - Data Analysis
  - An치lisis de Datos

---

<div align="justify" markdown="1">

Hemos llegado a un emocionante punto en nuestra b칰squeda para encontrar el modelo perdido que prediga los resultados de la PAES. En nuestro 칰ltimo cap칤tulo, exploramos c칩mo utilizar ChatGPT para generar c칩digo de Random Forest, una t칠cnica poderosa en el aprendizaje autom치tico.

Si a칰n no has le칤d@ el cap칤tulo anterior, te invito a [echarle un vistazo](https://daniavm.github.io/machine%20learning/en-busca-del-modelo-perdido-parte-3/) para obtener una visi칩n general de c칩mo ChatGPT nos ayud칩 a dar los primeros pasos en la creaci칩n de nuestro modelo predictivo.

## 游쓇릛 Explorando el Random Forest 游쓇릛

Ahora, nos tomaremos un descanso en el recorrido para profundizar en la t칠cnica de Random Forest. Imagina que est치s en medio de un bosque rodeado de 치rboles que, en lugar de solo estar vivos, cada uno de ellos representa una versi칩n 칰nica de tu b칰squeda en la traves칤a hacia el modelo perdido. Las ra칤ces, ramas y hojas representan de alguna manera las decisiones que has tomado en los distintos puntos de tu traves칤a y cada 치rbol termina siendo una historia de lo que hiciste en cada camino tomado.

Si no te queda del todo claro, bueno, ese es uno de los motivos por los cuales construir esta publicaci칩n. Es decir, la idea de hacernos un poco m치s conocedor칝s de estas representaciones para usarlas en casos reales.

### 游꺕 Nodos y Ramificaci칩n 游꺕

En este espeso bosque de decisiones, cada versi칩n de ti comienza en lo que llamamos el nodo ra칤z. En este momento, eres t칰 quien est치 en el bosque, y te enfrentas a una encrucijada crucial en tu b칰squeda del modelo perdido. En este punto inicial donde debes tomar una decisi칩n se dice que te encuentras en un nodo dispuesto a ramificarse. Las ramas ser치n aquellos posibles caminos que pudiste tomar o que tomaste.

**Ejemplo:** Te encuentras en el nodo ra칤z del primer 치rbol de decisi칩n. Aqu칤, enfrentas la primera decisi칩n clave: 쯇or d칩nde comenzar tu b칰squeda? 쯊omar el camino de la derecha, que parece m치s transitado, o aventurarte a explorar el camino menos recorrido junto al riachuelo? Esta elecci칩n da lugar a tu primera rama en el 치rbol de decisiones.

A medida que avanzas en tu b칰squeda, te enfrentar치s a una serie de decisiones como "쮻eber칤a recopilar m치s datos?" o "쯈u칠 enfoque debo utilizar para construir el modelo?". Cada uno de estas decisiones representa un nodo en nuestro **치rbol de decisi칩n**.

### 游 Poda y Ramas 游

Para mantener tus 치rboles de decisiones saludable, a menudo realizas una t칠cnica llamada poda. La poda implica eliminar caminos que no son 칰tiles o que pueden causar confusi칩n en tu b칰squeda. Esto ayuda a que tu bosque de decisiones sea m치s eficiente y preciso (recuerda que a nivel de la programaci칩n, mientras menos procesos innecesarios incluyas m치s r치pido procesar치 tu algoritmo).

Cada camino que creas desde el nodo ra칤z hasta una hoja se llama una rama o un sub-치rbol. Cada rama es un camino diferente que podr칤as tomar en tu b칰squeda en busca del modelo perdido.

**Ejemplo:** Al seguir tu elecci칩n inicial del camino de la derecha, te das cuenta de que algunas de las decisiones que tomaste no te acercaron al modelo perdido. De hecho te podr칤an haber llevado a un precipicio cno la 칰nica opci칩n de devolverte. Situaciones como esa son en las que optas por podar esas decisiones in칰tiles, dejando solo las que realmente importan en tu b칰squeda... aquellas que conducen a tu objetivo.

### 游꺕 PMadres e Hij@s: La Jerarqu칤a del Bosque 游꺕

Dentro de nuestro 치rbol de decisiones, los nodos forman una jerarqu칤a, similar a una familia o una organizaci칩n. Cada nodo de decisi칩n tiene un rol espec칤fico, y algunos act칰an como nodos padres, mientras que otros son nodos hijos. 

### Nodos Padres

Estos nodos son como tus mentores o supervisores en tu b칰squeda. En lugar de tomar decisiones directamente, gu칤an tu camino y dirigen tus acciones. Son responsables de dividir el camino en m칰ltiples opciones, creando as칤 nodos hijos que representan diferentes rutas que puedes seguir.

### Nodos Hijos

Los nodos hij@s son como tus compa침eros de viaje. Est치n conectados a los nodos pmadres a trav칠s de caminos, lo que significa que sigues las indicaciones de un nodo pmadre para llegar a un nodo hij@. Cada nodo hij@ representa una elecci칩n espec칤fica que puedes hacer en tu b칰squeda en busca del modelo que andas buscando.

Como dato interesante, creo que podr치s notar que un nodo hij@ puede convertirse en un nodo pmadre para as칤 abrir paso a nuevos hij@s. Todo depender치 de la cantidad de posibilidades que te ofrezca el camino (lo que en un caso pr치ctico representar치n los datos que has extraido, ya que por cada uno de esos valores alguien tuvo que tomar la decisi칩n de medirlos 쯡o?).

**Ejemplo:** Imagina que est치s en el bosque y llegas a un cruce de caminos. En este punto, te encuentras con un "nodo pmadre" que te ofrece tres opciones: tomar el camino de la izquierda, seguir el camino recto o aventurarte por el camino de la derecha. Cada uno de estos caminos est치 representado por un nodo hij@. Sigues uno de estos caminos seg칰n la elecci칩n que hagas en ese nodo pmadre.


## 游꺕游꺕 Par치metros n_estimators y random_state 游꺕游꺕

La historia que sea que se cuente se puede representar en cada uno de estos 치rboles, por lo que cada uno de ellos es como una bit치cora o un diario de vida que habla de la traves칤a que alguien que tuvo 칠xito o fracas칩 en su b칰squeda. Si tuvieramos la posibilidad de tomar al azar una cierta cantidad de estos diarios, entonces tendr칤amos una idea de cuantos lograron llegar al modelo y cu치ntos no. 

Hablando un poco ahora de programaci칩n, hemos de recordar algo del c칩digo mostrado en la publicaci칩n anterior. Uno de los par치metros m치s importantes es `n_estimators`, que determina cu치ntos de estos "diarios" de decisiones debes considerar en tu bosque. Cada diario representa una versi칩n 칰nica de tu b칰squeda cuando avanzas hacia el modelo perdido.

**Ejemplo:** Imagina que mientras avanzas en tu b칰squeda, decides llevar varios diarios para documentar todas tus decisiones. 쮺u치ntos diarios necesitas para obtener una imagen precisa de tus acciones y decisiones para llegar a tu objetivo? En esta situaci칩n, determinar la cantidad de diarios es an치logo a saber la cantidad de 치rboles de deber치s considerar para tomar tus decisiones.

En la misma l칤nea del c칩digo, otro par치metro importante es `random_state`, que se encarga de controlar la aleatoriedad en la creaci칩n de tus diarios de decisiones.

**Ejemplo:** Si configuramos `random_state` en 42, tus diarios siempre seguir치n el mismo patr칩n de decisiones (elegir치s siempre los mismos "diarios"). Esto es 칰til cuando deseas comparar resultados o depurar el modelo de manera consistente. En csao de que busques una elecci칩n distinta de "diarios", entonces no defines este par치metro.


## 游游 En Resumen: Navegando el Bosque de Random Forest 游游

As칤 como un aventurero toma decisiones cruciales para encontrar el tesoro perdido, Random Forest toma decisiones basadas en los datos para construir un modelo poderoso. Cada nodo, rama, hoja y diario representa una elecci칩n y una conclusi칩n. La jerarqu칤a de nodos padres e hijos organiza el camino en el bosque de decisiones.

Como ver치s, el modelo creado no tiene pre-establecida la idea de que debe haber un comportamiento espec칤fico en los datos, lo que lo hace tremendamente versatil a muchas situaciones de las cuales no podemos reconocer alg칰n patr칩n en espec칤fico. 

Mientras exploramos el Random Forest, ten en cuenta que no seguimos un solo 치rbol de decisi칩n, sino un bosque completo de ellos. Cada 치rbol ofrece su propia perspectiva sobre c칩mo alcanzar nuestro objetivo.

<img src="{{https://daniavm.github.io}}{{ site.baseurl }}/assets/images/PAES_prediction_model/modelo_perdido_cap4_analogia.gif" alt="">

<div align="right" markdown="1">

_Hasta el pr칩ximo cronopunto del Principia 游볰._

DV

</div>

---

</div>
