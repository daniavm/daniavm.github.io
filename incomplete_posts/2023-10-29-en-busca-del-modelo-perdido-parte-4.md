---
title: "En Busca del Modelo Perdido - Parte 4: Los Secretos del Random Forest"
layout: single
author_profile: true
related: true
comments: true
toc: false

header:
  image: /assets/images/PAES_prediction_model/RandomForestBanner.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestBanner.jpg

categories:
  - Machine Learning
  - Aprendizaje Autom치tico
  - Artificial Intelligence
  - Inteligencia Artificial
  - Data Science
  - Ciencia de Datos
  - Model Building
  - Construcci칩n de Modelos
tags:
  - Random Forest
  - Bosque Aleatorio
  - Decision Trees
  - 츼rboles de Decisi칩n
  - Machine Learning Models
  - Modelos de Aprendizaje Autom치tico
  - Model Evaluation
  - Evaluaci칩n de Modelos
  - Feature Engineering
  - Ingenier칤a de Caracter칤sticas
  - Python Programming
  - Programaci칩n en Python
  - Data Preprocessing
  - Procesamiento de Datos
  - Data Analysis
  - An치lisis de Datos


---

<div align="justify" markdown="1">

Hemos llegado a un emocionante punto en nuestra b칰squeda para encontrar el modelo perdido que prediga los resultados de la PAES. En nuestro 칰ltimo cap칤tulo, exploramos c칩mo utilizar ChatGPT para generar c칩digo de Random Forest, una t칠cnica poderosa en el aprendizaje autom치tico.

Si a칰n no has le칤d@ el cap칤tulo anterior, te invito a [echarle un vistazo](https://daniavm.github.io/machine%20learning/en-busca-del-modelo-perdido-parte-3/) para obtener una visi칩n general de c칩mo ChatGPT nos ayud칩 a dar los primeros pasos en la creaci칩n de nuestro modelo predictivo.

## 游쓇릛 Explorando el Random Forest 游쓇릛

Ahora, nos tomaremos un descanso en el recorrido para profundizar en la t칠cnica de Random Forest. Imagina que est치s en medio de un bosque rodeado de 치rboles que, en lugar de solo estar vivos, cada uno de ellos representa una versi칩n 칰nica de tu b칰squeda en la traves칤a hacia el modelo perdido. Las ra칤ces, ramas y hojas representan de alguna manera las decisione sque has tomado en los distintos puntos de tu traves칤a y cada 치rbol termina siendo una historia de lo que hiciste en cada camino tomado.

Si no te queda del todo claro, bueno ese es uno de los motivos por los que construir esta publicaci칩n. Hacernos un poco m치s conocedor칝s de estas representaciones para usarlas en casos reales.

### 游꺕 Nodos y Ramificaci칩n 游꺕

En este espeso bosque de decisiones, cada versi칩n de ti comienza en lo que llamamos el nodo ra칤z. En este momento, eres t칰 quien est치 en el bosque, y te enfrentas a una encrucijada crucial en tu b칰squeda del modelo perdido. En este punto inicial donde debes tomar una decisi칩n se dice que te encuentras en un nodo dispuesto a ramificarse. Las ramas ser치n aquellos posibles caminos que pudiste tomar o que tomaste.

**Ejemplo:** Te encuentras en el nodo ra칤z del primer 치rbol de decisi칩n. Aqu칤, enfrentas la primera decisi칩n clave: 쯇or d칩nde comenzar tu b칰squeda? 쯊omar el camino de la derecha, que parece m치s transitado, o aventurarte a explorar el camino menos recorrido junto al riachuelo? Esta elecci칩n da lugar a tu primera rama en el 치rbol de decisiones.

A medida que avanzas en tu b칰squeda, tomas una serie de decisiones, como "쮻eber칤a recopilar m치s datos?" o "쯈u칠 enfoque debo utilizar para construir el modelo?".

![Ejemplo 1: La Ra칤z](/assets/images/PAES_prediction_model/modelo_perdido_cap4_raices.gif)
<img src="{{https://daniavm.github.io}}{{ site.baseurl }}/assets/images/PAES_prediction_model/modelo_perdido_cap4_raices.gif" alt="">

### 游 Poda y Ramas 游

Para mantener tu bosque de decisiones saludable, a menudo realizas una t칠cnica llamada poda. La poda implica eliminar caminos que no son 칰tiles o que pueden causar confusi칩n en tu b칰squeda. Esto ayuda a que tu bosque de decisiones sea m치s eficiente y preciso.

Cada camino que creas desde el nodo ra칤z hasta una hoja se llama una rama o un sub-치rbol. Cada rama es un camino diferente que podr칤as tomar en tu b칰squeda en busca del modelo perdido.

**Ejemplo:** Al seguir tu elecci칩n inicial del camino de la derecha, te das cuenta de que algunas de las decisiones que tomaste no te acercaron al modelo perdido. Decides podar esas decisiones in칰tiles, dejando solo las que realmente importan en tu b칰squeda.

![Ejemplo 3: Hojas y Poda](/assets/images/RandomForestPruningExample.png)

### 游꺕 PMadres e Hij@s: La Jerarqu칤a del Bosque 游꺕

Dentro de nuestro bosque de decisiones, los nodos de decisi칩n forman una jerarqu칤a, similar a una familia. Cada nodo de decisi칩n tiene un rol espec칤fico, y algunos act칰an como nodos padres, mientras que otros son nodos hijos.

### Nodos Padres

Estos nodos son como tus mentores o supervisores en tu b칰squeda. En lugar de tomar decisiones directamente, gu칤an tu camino y dirigen tus acciones. Son responsables de dividir el camino en m칰ltiples opciones, creando as칤 nodos hijos que representan diferentes rutas que puedes seguir.

### Nodos Hijos

Los nodos hijos son como tus compa침eros de viaje. Est치n conectados a los nodos padres a trav칠s de caminos, lo que significa que sigues las indicaciones de un nodo padre para llegar a un nodo hijo. Cada nodo hijo representa una elecci칩n espec칤fica que puedes hacer en tu b칰squeda en busca del modelo perdido.

**Ejemplo:** Imagina que est치s en el bosque y llegas a un cruce de caminos. En este punto, te encuentras con un nodo padre que te ofrece tres opciones: tomar el camino de la izquierda, seguir el camino recto o aventurarte por el camino de la derecha. Cada uno de estos caminos est치 representado por un nodo hijo. Sigues uno de estos caminos seg칰n la elecci칩n que hagas en ese nodo padre.

![Ejemplo 2: Nodos, Ramificaci칩n y Jerarqu칤a](/assets/images/RandomForestHierarchyExample.png)

## 游꺕游꺕 Par치metros n_estimators y random_state 游꺕游꺕

Uno de los par치metros m치s importantes es `n_estimators`, que determina cu치ntos de estos diarios de decisiones debes crear en tu bosque. Cada diario representa una versi칩n 칰nica de tu b칰squeda en busca del modelo perdido.

**Ejemplo:** Imagina que mientras avanzas en tu b칰squeda, decides llevar varios diarios para documentar tus decisiones. 쮺u치ntos diarios necesitas para obtener una imagen precisa de tus acciones y decisiones?

Otro par치metro importante es `random_state`, que se encarga de controlar la aleatoriedad en la creaci칩n de tus diarios de decisiones.

**Ejemplo:** Si configuramos `random_state` en 42, tus diarios siempre seguir치n el mismo patr칩n de decisiones. Esto es 칰til cuando deseas comparar resultados o depurar el modelo de manera consistente.

![Ejemplo 4: Par치metro n_estimators](/assets/images/RandomForestNestimatorsExample.png)

## 游游 En Resumen: Navegando el Bosque de Random Forest 游游

As칤 como un aventurero toma decisiones cruciales para encontrar el tesoro perdido, Random Forest toma decisiones basadas en los datos para construir un modelo poderoso. Cada nodo, rama, hoja y diario representa una elecci칩n y una conclusi칩n. La jerarqu칤a de nodos padres e hijos organiza el camino en el bosque de decisiones.

Mientras exploramos el Random Forest, ten en cuenta que no seguimos un solo 치rbol de decisi칩n, sino un bosque completo de ellos. Cada 치rbol ofrece su propia perspectiva sobre c칩mo alcanzar nuestro objetivo.

<div align="right" markdown="1">

_Hasta el pr칩ximo cronopunto del Principia 游볰._

DV

</div>

---

</div>
