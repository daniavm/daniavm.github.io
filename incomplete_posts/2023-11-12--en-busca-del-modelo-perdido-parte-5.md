---
title: "En Busca del Modelo Perdido - Parte 5: Afinando el Random Forest"
layout: single
author_profile: true
related: true
comments: true
toc: false

header:
  image: /assets/images/PAES_prediction_model/RandomForestComplex.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestComplex_teaser.jpg

categories:
  - Machine Learning
  - Aprendizaje Autom谩tico
  - Data Science
  - Ciencia de Datos
  - Educational Data Mining
  - Miner铆a de Datos Educativos

tags:
  - Random Forest
  - Validaci贸n Cruzada
  - Optimizaci贸n de Modelos
  - Predicci贸n de Resultados
  - PAES
  - Ense帽anza
---

# En Busca del Modelo Perdido - Parte 5: Afinando el Random Forest

Continuando nuestra exploraci贸n en el mundo del an谩lisis de datos, nos enfrentamos ahora al desaf铆o de afinar nuestro modelo de Random Forest. En este cap铆tulo, nos centramos en entender mejor las decisiones detr谩s de nuestra programaci贸n y el impacto que tienen en los resultados finales.

##  Comprendiendo el Porqu茅 Detr谩s del C贸digo 

Cada l铆nea de c贸digo en un an谩lisis de datos tiene un prop贸sito y puede influir significativamente en el resultado final. Es esencial entender el 'porqu茅' detr谩s de cada funci贸n y par谩metro para ser capaz de confiar y explicar los resultados de nuestro modelo.

Para no olvidar nuestro trabajo hasta ahora, te comparto el c贸digo que dejamos en el cap铆tulo 3:

<script src="https://gist.github.com/daniavm/2b929e13e7438d3d40123a43149d40ff.js"></script>

### 驴Por qu茅 dividimos los datos?

```python
from sklearn.model_selection import train_test_split

# Dividimos los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

La funci贸n '***train_test_split***' es una herramienta que divide nuestros datos en dos partes: un conjunto para entrenar nuestro modelo y otro para probarlo. El test_size=0.2 significa que el 20% de los datos se reservan para probar el modelo, mientras que el resto se utiliza para el entrenamiento. Pero, 驴por qu茅 20% y no otro n煤mero? Elegir el tama帽o del conjunto de prueba es una decisi贸n que puede afectar la precisi贸n de nuestras predicciones. Un conjunto de prueba demasiado peque帽o puede no capturar la variabilidad de los datos, mientras que uno demasiado grande podr铆a no dejar suficientes datos para entrenar el modelo adecuadamente.

### La Importancia de la Validaci贸n Cruzada
La validaci贸n cruzada es como un examen riguroso para nuestro modelo. En lugar de solo un test, nuestro modelo debe pasar m煤ltiples pruebas, mejorando as铆 su robustez y confiabilidad.


from sklearn.model_selection import cross_val_score, KFold

# Configuramos la validaci贸n cruzada
kf = KFold(n_splits=5)
cross_val_scores = cross_val_score(model, X, y, cv=kf)


KFold es una t茅cnica que divide nuestros datos en 'k' partes, o 'folds', y luego realiza 'k' pruebas diferentes, cada una usando una parte diferente como conjunto de prueba. cross_val_score toma nuestro modelo y datos y aplica esta t茅cnica para evaluar qu茅 tan bien est谩 realizando el modelo.

Explorando el N煤mero de Estimadores y Folds
El siguiente paso fue explorar c贸mo el n煤mero de estimadores y 'folds' afecta el rendimiento del modelo. Este proceso es fundamental para afinar nuestro modelo y asegurar que se generalice bien a nuevos datos.

# Experimento con diferentes cantidades de estimadores y 'folds'
for fold in range(2, 80):
    kf = KFold(n_splits=fold)
    model = RandomForestRegressor(n_estimators=100)
    mae_score = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error').mean()
    print(f"{fold} folds: MAE = {mae_score}")


El bucle for en Python nos permite probar una serie de valores en un proceso iterativo, lo cual es ideal para experimentar con diferentes configuraciones de nuestro modelo. Aqu铆, estamos buscando el 'fold' 贸ptimo que minimice el Error Absoluto Medio (MAE), una medida de qu茅 tan lejos est谩n nuestras predicciones de los valores reales.

## El Viaje hacia un Modelo M谩s Preciso
Al final, lo que buscamos es un modelo que nos ofrezca predicciones confiables. Para llegar a esto, hemos refinado nuestro Random Forest y ahora miramos hacia los resultados reales.

# Visualizaci贸n de los resultados del modelo
plt.figure(figsize=(10, 6))
plt.scatter(y, y_pred, alpha=0.5)
plt.xlabel('Valores Reales de PAES')
plt.ylabel('Predicciones de PAES')
plt.title('Comparaci贸n de Valores Reales y Predicciones')
plt.grid()
plt.show()


Esta visualizaci贸n es crucial. Al comparar los valores reales y las predicciones con un gr谩fico de dispersi贸n, podemos ver visualmente la precisi贸n de nuestro modelo. Si los puntos se alinean cerca de una l铆nea imaginaria diagonal, nuestro modelo est谩 en buen camino.

##  Lecciones Aprendidas y Camino a Seguir 
Este cap铆tulo nos ha llevado a trav茅s de una exploraci贸n detallada de c贸mo ajustar nuestro modelo de Random Forest. Hemos aprendido que cada par谩metro cuenta su propia historia y que solo a trav茅s de la comprensi贸n y la experimentaci贸n podemos esperar acercarnos a la verdad detr谩s de nuestros datos.

En la pr贸xima etapa de nuestro viaje, continuaremos afinando nuestro modelo, siempre con la mente abierta y dispuestos a aprender de los datos que tenemos entre manos.

Hasta entonces, nos vemos en el pr贸ximo cronopunto del Principia .

DV