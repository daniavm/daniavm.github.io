---
title: "En Busca del Modelo Perdido - Parte 5: Afinando el Random Forest"
layout: single
author_profile: true
related: true
comments: true
toc: false

header:
  image: /assets/images/PAES_prediction_model/RandomForestComplex.jpg
  teaser: /assets/images/PAES_prediction_model/RandomForestComplex_teaser.jpg

categories:
  - Machine Learning
  - Aprendizaje Autom치tico
  - Data Science
  - Ciencia de Datos
  - Educational Data Mining
  - Miner칤a de Datos Educativos

tags:
  - Random Forest
  - Validaci칩n Cruzada
  - Optimizaci칩n de Modelos
  - Predicci칩n de Resultados
  - PAES
  - Ense침anza
---

<div align="justify" markdown="1">
Continuando nuestra exploraci칩n en el mundo del an치lisis de datos, nos enfrentamos ahora al desaf칤o de afinar nuestro modelo de Random Forest. En este cap칤tulo, nos centramos en entender mejor las decisiones detr치s de nuestra programaci칩n y el impacto que tienen en los resultados finales.

## 游꿉 Comprendiendo el Porqu칠 Detr치s del C칩digo 游꿉

Cada l칤nea de c칩digo en un an치lisis de datos tiene un prop칩sito y puede influir significativamente en el resultado final. Es esencial entender el 'porqu칠' detr치s de cada funci칩n y par치metro para ser capaz de confiar y explicar los resultados de nuestro modelo.

Para no olvidar nuestro trabajo hasta ahora, te comparto el c칩digo que dejamos en el cap칤tulo 3:

<script src="https://gist.github.com/daniavm/2b929e13e7438d3d40123a43149d40ff.js"></script>

A pesar de ser un c칩digo que entrega resultados prometedores, a칰n nos falta saber si es posible acercarnos a un nivel de confiabilidad superior y conciente. Para lograr esto 칰ltimo, comenzaremos entonces por analizar las piezas de c칩digo que son fundamentales. 

### 쯇or qu칠 dividimos los datos?

```python
from sklearn.model_selection import train_test_split

# Dividimos los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

La funci칩n '***train_test_split***' es una herramienta que divide nuestros datos en dos partes: un conjunto para entrenar nuestro modelo y otro para probarlo. El test_size=0.2 significa que el 20% de los datos se reservan para probar el modelo, mientras que el resto se utiliza para el entrenamiento. Pero, 쯣or qu칠 20% y no otro n칰mero? Elegir el tama침o del conjunto de prueba es una decisi칩n que puede afectar la precisi칩n de nuestras predicciones. Un conjunto de prueba demasiado peque침o puede no capturar la variabilidad de los datos, mientras que uno demasiado grande podr칤a no dejar suficientes datos para entrenar el modelo adecuadamente.

### La Importancia de 'n_estimators' y 'random_state'

```python
from sklearn.ensemble import RandomForestRegressor

# Creamos el modelo de Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42)
```

El par치metro ***n_estimators*** determina cu치ntos 치rboles incluir en nuestro bosque. Cien 치rboles es un buen punto de partida, pero no hay una respuesta 칰nica para todos los casos. Necesitamos equilibrar la complejidad del modelo con la capacidad de generalizar bien a nuevos datos.

El ***random_state*** es nuestra semilla de aleatoriedad. Utilizar un n칰mero fijo, como 42, garantiza que si repetimos el an치lisis obtendremos los mismos resultados. Esto es crucial para la reproducibilidad de nuestro estudio.


## 游댌 Refinando la Validaci칩n: Superando la Divisi칩n Est치tica 游댌

La divisi칩n est치ndar de los datos en un 80% para entrenamiento y un 20% para pruebas no siempre captura la complejidad y variabilidad inherentes en nuestro conjunto de datos. Para mejorar nuestra evaluaci칩n del modelo y asegurarnos de que es robusto y confiable, implementamos la validaci칩n cruzada.

```python
from sklearn.model_selection import cross_val_score, KFold

# Configuramos la validaci칩n cruzada
kf = KFold(n_splits=5)
cross_val_scores = cross_val_score(model, X, y, cv=kf)
```

La funci칩n '***KFold***' de '***sklearn***' nos permite dividir el conjunto de datos en m칰ltiples segmentos o 'folds'. A diferencia de una 칰nica divisi칩n de entrenamiento/prueba, la validaci칩n cruzada eval칰a el modelo en varias rondas, utilizando cada vez un segmento diferente como conjunto de prueba y el resto como entrenamiento. Esto garantiza que cada muestra de los datos se utilice tanto para entrenar como para validar el modelo, d치ndonos una medida m치s fiable de su rendimiento y evitando que ciertas peculiaridades de los datos influyan de manera desproporcionada en los resultados.

# Experimento con diferentes cantidades de estimadores y 'folds'
for fold in range(2, 80):
    kf = KFold(n_splits=fold)
    model = RandomForestRegressor(n_estimators=100)
    mae_score = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error').mean()
    print(f"{fold} folds: MAE = {mae_score}")


El bucle for en Python nos permite probar una serie de valores en un proceso iterativo, lo cual es ideal para experimentar con diferentes configuraciones de nuestro modelo. Aqu칤, estamos buscando el 'fold' 칩ptimo que minimice el Error Absoluto Medio (MAE), una medida de qu칠 tan lejos est치n nuestras predicciones de los valores reales.

## El Viaje hacia un Modelo M치s Preciso
Al final, lo que buscamos es un modelo que nos ofrezca predicciones confiables. Para llegar a esto, hemos refinado nuestro Random Forest y ahora miramos hacia los resultados reales.

# Visualizaci칩n de los resultados del modelo
plt.figure(figsize=(10, 6))
plt.scatter(y, y_pred, alpha=0.5)
plt.xlabel('Valores Reales de PAES')
plt.ylabel('Predicciones de PAES')
plt.title('Comparaci칩n de Valores Reales y Predicciones')
plt.grid()
plt.show()


Esta visualizaci칩n es crucial. Al comparar los valores reales y las predicciones con un gr치fico de dispersi칩n, podemos ver visualmente la precisi칩n de nuestro modelo. Si los puntos se alinean cerca de una l칤nea imaginaria diagonal, nuestro modelo est치 en buen camino.

## 游꿉 Lecciones Aprendidas y Camino a Seguir 游꿉
Este cap칤tulo nos ha llevado a trav칠s de una exploraci칩n detallada de c칩mo ajustar nuestro modelo de Random Forest. Hemos aprendido que cada par치metro cuenta su propia historia y que solo a trav칠s de la comprensi칩n y la experimentaci칩n podemos esperar acercarnos a la verdad detr치s de nuestros datos.

En la pr칩xima etapa de nuestro viaje, continuaremos afinando nuestro modelo, siempre con la mente abierta y dispuestos a aprender de los datos que tenemos entre manos.

Hasta entonces, nos vemos en el pr칩ximo cronopunto del Principia 游볰.

DV

</div>